{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ISTM660 11/8/2019 ICE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xihengjing/xjing/blob/master/Text-mining%20classification%20model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaAHGF2lbTQQ"
      },
      "source": [
        "# **Introduction**\n",
        "\n",
        "This project outlines a text-mining classification model using bag-of-words and logistic regression. We will attempt to understand the relationship between Amazon text reviews on earphones and review ratings. Unstructured data analysis will be conducted and there will be some experience with statistics and/or other classification experience.\n",
        "\n",
        "\n",
        "Data Source: [Kaggle](https://www.kaggle.com/purvank/uber-rider-reviews-dataset/data) by user *Shital Kat*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0kUMX2GbbjW"
      },
      "source": [
        "\n",
        "\n",
        "*   Preliminary Analysis\n",
        "*   Formatting / Converting Text\n",
        "*   Logistic Regression\n",
        "*   Testing / Conclusions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSSuXGbGbxFg"
      },
      "source": [
        "**Preliminary Analysis**\n",
        "\n",
        "Import Data\n",
        "First let‚Äôs bring in the data and visualize the dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ338kOx3sMh",
        "cellView": "both"
      },
      "source": [
        "#@title Importing Modules\n",
        "#importing modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx-JZrHgNDra",
        "cellView": "both",
        "outputId": "3e997b89-9069-413d-b6f4-f856d198d3fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "#@title Code to import file from colab files (Example 2)\n",
        "df = pd.read_csv('/content/AllProductReviews.csv')\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-22e127bcfdec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title Code to import file from colab files (Example 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/AllProductReviews.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/AllProductReviews.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53MHxS-4IRoz",
        "cellView": "both",
        "outputId": "0368b804-9b07-411b-e888-d7b497973148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#@title Load data\n",
        "url = 'https://raw.githubusercontent.com/xihengjing/xjing/master/AllProductReviews.csv'\n",
        "\n",
        "# Load data into a pandas dataframe\n",
        "df = pd.read_csv(url)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ReviewTitle</th>\n",
              "      <th>ReviewBody</th>\n",
              "      <th>ReviewStar</th>\n",
              "      <th>Product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Honest review of an edm music lover\\n</td>\n",
              "      <td>No doubt it has a great bass and to a great ex...</td>\n",
              "      <td>3</td>\n",
              "      <td>boAt Rockerz 255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Unreliable earphones with high cost\\n</td>\n",
              "      <td>This  earphones are unreliable, i bought it be...</td>\n",
              "      <td>1</td>\n",
              "      <td>boAt Rockerz 255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Really good and durable.\\n</td>\n",
              "      <td>i bought itfor 999,I purchased it second time,...</td>\n",
              "      <td>4</td>\n",
              "      <td>boAt Rockerz 255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>stopped working in just 14 days\\n</td>\n",
              "      <td>Its sound quality is adorable. overall it was ...</td>\n",
              "      <td>1</td>\n",
              "      <td>boAt Rockerz 255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Just Awesome Wireless Headphone under 1000...üòâ\\n</td>\n",
              "      <td>Its Awesome... Good sound quality &amp; 8-9 hrs ba...</td>\n",
              "      <td>5</td>\n",
              "      <td>boAt Rockerz 255</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        ReviewTitle  ...           Product\n",
              "0             Honest review of an edm music lover\\n  ...  boAt Rockerz 255\n",
              "1             Unreliable earphones with high cost\\n  ...  boAt Rockerz 255\n",
              "2                        Really good and durable.\\n  ...  boAt Rockerz 255\n",
              "3                 stopped working in just 14 days\\n  ...  boAt Rockerz 255\n",
              "4  Just Awesome Wireless Headphone under 1000...üòâ\\n  ...  boAt Rockerz 255\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6fVRdi3NnRa",
        "cellView": "both",
        "outputId": "9d633845-98ec-42ad-e1b6-a231cdbf6f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#@title Choosing apprpiate columns\n",
        "df2 = df[['ReviewBody', 'ReviewStar']] \n",
        "df = df2\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ReviewBody</th>\n",
              "      <th>ReviewStar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No doubt it has a great bass and to a great ex...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This  earphones are unreliable, i bought it be...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i bought itfor 999,I purchased it second time,...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Its sound quality is adorable. overall it was ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Its Awesome... Good sound quality &amp; 8-9 hrs ba...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          ReviewBody  ReviewStar\n",
              "0  No doubt it has a great bass and to a great ex...           3\n",
              "1  This  earphones are unreliable, i bought it be...           1\n",
              "2  i bought itfor 999,I purchased it second time,...           4\n",
              "3  Its sound quality is adorable. overall it was ...           1\n",
              "4  Its Awesome... Good sound quality & 8-9 hrs ba...           5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L9eyeg7cMnf"
      },
      "source": [
        "It‚Äôs a straightforward dataset. We have the \"ReviewBody‚Äù text column and the ‚ÄúReviewStar‚Äù column (which ranges from 1 as the lowest rating and 5 as the highest). Users write these text reviews to describe their experience and the categorical 5 star rating summarizes it.\n",
        "\n",
        "**Basic Statistics**\n",
        "\n",
        "Let‚Äôs check the .describe() method to see how many instances we‚Äôre dealing with and other basic statistics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMtDSQSK4Ic4",
        "outputId": "80e46c9f-4ae9-42d8-b511-661bdcbfb0fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "df.describe() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ReviewStar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>14337.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.675874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.503409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ReviewStar\n",
              "count  14337.000000\n",
              "mean       3.675874\n",
              "std        1.503409\n",
              "min        1.000000\n",
              "25%        3.000000\n",
              "50%        4.000000\n",
              "75%        5.000000\n",
              "max        5.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRwX2Xbtcbk5"
      },
      "source": [
        "It appears the customers' response on this particular earphone is fairly well in this sample. The mean rating is 3.68, and the 25% mark is a 3 star review, meaning that 75% of the reviews are above 3. Also, the 75% mark of a 5 star rating means that we have at least 25% of ratings at 5 star. This shows that the data is skewed to the right. Hopefully we can gain some insight into this by building a model.\n",
        "\n",
        "**Purpose of Model**\n",
        "\n",
        "Having mentioned that, let‚Äôs reiterate the utility of the bag of words / logistic regression model we will build:\n",
        "\n",
        "\n",
        "*   We will be able to gauge the sentiment of future text reviews and categorize them into ‚ÄúGood‚Äù or ‚ÄúBad‚Äù classes.\n",
        "*   We will be able to pinpoint specific words with a high impact on rating sentiment. This information could be an asset for the sellers and Amazon (if used for their entire internal dataset ‚Äî not this small sample we have). For example, the word ‚Äúrude‚Äù likely has a negative coefficient, pushing our classifier to label that review as bad. The word ‚Äúgreat‚Äù likely has a positive coefficient, pushing our classifier to label that review as good. The goal is discovery. We don‚Äôt know what interesting words may appear to have an impact on sentiment, and that‚Äôs the fun part. Does the word ‚Äúgreat‚Äù outweigh ‚Äúhorrible‚Äù and net positive or negative? Many questions like this will be answered with our model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7qs1J85ctu0"
      },
      "source": [
        "**Null Check**\n",
        "\n",
        "Moving on, let‚Äôs check for null values in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkO7fhKBc0sN",
        "outputId": "3efd7f10-62b5-4f9f-9541-c802e52231aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#checking for nulls\n",
        "null_count = df.isnull().sum()\n",
        "null_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ReviewBody    0\n",
              "ReviewStar    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RwrCnoYcyVE"
      },
      "source": [
        "None this time. If we had some nulls, we would need to explore how to deal with those. Many good resources exist on this topic you can research."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UU5VZOCc67q"
      },
      "source": [
        "**Distributions**\n",
        "\n",
        "Next, let‚Äôs visualize the rating distribution of our data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXzNsYGNc_jC",
        "cellView": "both",
        "outputId": "9a1e3e44-d48b-40c0-c5e7-cf1a6608033e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "#@title Visualization\n",
        "#seperating by groups\n",
        "groups = df.groupby('ReviewStar').count()\n",
        "Values = groups.ReviewBody\n",
        "colors = ['r', 'g', 'b', 'c', 'm']\n",
        "#making bar plot\n",
        "plt.bar([1,2,3,4,5], Values, color = colors)\n",
        "plt.title('Rating Distribution')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Review Quantity')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoDGbLYHdPz_"
      },
      "source": [
        "**Logistic Regression**\n",
        "\n",
        "In statistics, the logistic model (or logit model) uses a logistics function to model a binary dependent variable. The dependent variable or the outcome would usually have binary results, either success or fail(1 or 0), or in other cases, like/dislike, good/bad, etc.. The logistics function will predict the rate or probability of the success event in multiple groups. For example, coronary issues would grow gradually with raising age, and hence the probability of coronary issues happening will grow from lower age groups to higher age groups. The probability of each group will add up to one. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuxGZyWOdEQL"
      },
      "source": [
        "**Setiment Rule**\n",
        "\n",
        "In order to perform the logistic regression later, we need to figure out a way to turn these 5 ratings categories into binary classes (1 and 0). Remember, logistic regression only handles ‚Äúeither/or‚Äù target variables. The best way to turn the star ratings into binary classes(in my opinion) is:\n",
        "\n",
        "Set ratings below 3 stars as class 0 (negative sentiment)\n",
        "\n",
        "Set ratings above 3 as class 1 (positive sentiment)\n",
        "\n",
        "Delete the 3 star ratings. 3 stars are neutral and offer no sentiment insight.\n",
        "\n",
        "So, let‚Äôs make a new column that deletes the 3 star ratings and creates a new column which classifies the other ratings into binary classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvFlCTCfdlVK",
        "cellView": "both",
        "outputId": "c300c7da-d0d2-4972-a511-b30af4356eb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "#@title Dropping data that will not help in out modeling\n",
        "#deleting all instances with ReviewStar = 3\n",
        "df = df[df.ReviewStar != 3]\n",
        "#separating by groups\n",
        "groups = df.groupby('ReviewStar').count()\n",
        "Values = groups.ReviewBody\n",
        "colors = ['r', 'g', 'b', 'c']\n",
        "#making bar plot\n",
        "plt.bar([1,2,4,5], Values, color= colors)\n",
        "plt.title('Rating Distribution')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Review Quantity')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qetWiQChdq_O",
        "cellView": "both",
        "outputId": "b7536944-2caf-4ea2-b272-3a888c764ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "#@title Creating new binary_class column\n",
        "df['binary_class'] = np.where(df['ReviewStar'] > 3, 1, 0)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ReviewBody</th>\n",
              "      <th>ReviewStar</th>\n",
              "      <th>binary_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This  earphones are unreliable, i bought it be...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i bought itfor 999,I purchased it second time,...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Its sound quality is adorable. overall it was ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Its Awesome... Good sound quality &amp; 8-9 hrs ba...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>After 11 days, the charging port isn't working...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14332</th>\n",
              "      <td>Good\\n</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14333</th>\n",
              "      <td>An amazing product but a bit costly.\\n</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14334</th>\n",
              "      <td>Sound\\n</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14335</th>\n",
              "      <td>the sound is good battery life is good but the...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14336</th>\n",
              "      <td>M writing this review after using for almost 7...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12834 rows √ó 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              ReviewBody  ...  binary_class\n",
              "1      This  earphones are unreliable, i bought it be...  ...             0\n",
              "2      i bought itfor 999,I purchased it second time,...  ...             1\n",
              "3      Its sound quality is adorable. overall it was ...  ...             0\n",
              "4      Its Awesome... Good sound quality & 8-9 hrs ba...  ...             1\n",
              "5      After 11 days, the charging port isn't working...  ...             0\n",
              "...                                                  ...  ...           ...\n",
              "14332                                             Good\\n  ...             1\n",
              "14333             An amazing product but a bit costly.\\n  ...             1\n",
              "14334                                            Sound\\n  ...             0\n",
              "14335  the sound is good battery life is good but the...  ...             1\n",
              "14336  M writing this review after using for almost 7...  ...             0\n",
              "\n",
              "[12834 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SLmxjwbdxKp"
      },
      "source": [
        "# **Formatting / Converting Text**\n",
        "**Train/Test Split**\n",
        "\n",
        "The first step in this process is separating our data into training and testing sets. We will create our model from the training data and save some instances for testing purposes later. We‚Äôre using sklearn to shuffle and split. Without messing with the parameters, it should split our data into 75% training and 25% testing.\n",
        "\n",
        "By calling X_train.shape, we can check this. Further, let‚Äôs print a random review to verify it worked and to remind ourselves what we‚Äôre working with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXc6-FtPd5Xm",
        "cellView": "both",
        "outputId": "e836dde8-a1b2-4ecc-f3e8-f2335415686e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#@title Splitting into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['ReviewBody'], df['binary_class'], random_state = 0)\n",
        "#setting random number between 1 and 1000\n",
        "number = random.randint(1,1000)\n",
        "#printing random training text and X_train shape\n",
        "print ('Random Review:')\n",
        "print(' ')\n",
        "print(X_train[number])\n",
        "print(' ')\n",
        "print('X_train shape: ' + str(X_train.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Review:\n",
            " \n",
            "Sound quality is good phone reception quality is also good but am unable to play pubg using this because of it take 2sec time to receive sound from mobile while playing pubg\n",
            "\n",
            " \n",
            "X_train shape: (9625,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE6ZWO4NeLbG"
      },
      "source": [
        "**Turning words into numbers**\n",
        "\n",
        "Now comes the exciting part, translating our text data into numerical features. In order to run a regression though this data later, we need to have a feature for every word in our sample. Essentially, we will be translating each word to be assigned as a number and then counting the frequency of these word/numbers used per instance in matrices. The process of doing this is called **‚ÄúBag-of-words‚Äù**. It‚Äôs important to note that the order of words doesn‚Äôt matter, bag-of-words only counts the frequency per instance of words used. To start, we will use the Sklearn CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wDccJ7qeHV-",
        "cellView": "both",
        "outputId": "483b6002-91ad-43c7-cc83-cf6e0d09952c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Turning words into numbers\n",
        "#importing countvectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#creating variable which assigns X_train to numbers\n",
        "vect = CountVectorizer().fit(X_train)\n",
        "#translates numbers back to text\n",
        "vect.get_feature_names()[1:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['000', '001', '00bt', '00g', '02143121', '03', '04', '05', '06']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTtdlHNReujC"
      },
      "source": [
        "We can see using the len(vect.get_feature_names()) method, there are a total of 8,612 words in all the reviews:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwStGotWev9X",
        "outputId": "2f57c202-f55d-4bf7-b5a5-462dab3ee225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#length of total words\n",
        "len(vect.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8612"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_fZOkoee1gT"
      },
      "source": [
        "Now, let‚Äôs transform our X_train data into a matrix which contains the documents (instances) as rows and the count of new features (8,612) as columns. For example, our first word (0) as seen above is ‚Äú000‚Äù. That will be the first column in the matrix. Whichever reviews contain '000' will tally up how many times it was used and add it to that column. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6XlkgdEe2-I",
        "cellView": "both",
        "outputId": "72e893b7-0e12-40bf-93d8-af3753055b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#@title Creating matrix array for logistic regression\n",
        "X_train_vectorized = vect.transform(X_train)\n",
        "print (X_train_vectorized.toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5NWdarpe542"
      },
      "source": [
        "Because there are so many words and most reviews only have a small portion of them, most of the numbers in this array will be 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcAsF3QgfAv5"
      },
      "source": [
        "**Logistic Regression**\n",
        "\n",
        "**Building Model**\n",
        "\n",
        "We finally made it to the regression.\n",
        "Again, we will be using sklearn to perform this model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKdwDv8Ye9wB",
        "cellView": "both",
        "outputId": "d7bed3df-577a-4099-89fc-10ec5f114748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#@title Creating Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_vectorized, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1M9a0SZfNju"
      },
      "source": [
        "Now, we will calculate the AUC to see how well it classifies the test data.\n",
        "\n",
        "AUC (Area Under The Curve) ROC (Receiver Operating Characteristics)\n",
        "\n",
        "AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. By analogy, Higher the AUC, better the model is at distinguishing between good and bad reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUciFHhOfOob",
        "cellView": "both",
        "outputId": "781f46ae-a32f-4dc1-cf54-35f1d6dcd10b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Calculating AUC\n",
        "from sklearn.metrics import roc_auc_score\n",
        "predictions = model.predict(vect.transform(X_test))\n",
        "print('AUC: ', roc_auc_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.8575261440051657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x4DQR1RgB8w"
      },
      "source": [
        "This is good. A rough way of understanding this metric is to say we have 86% correctly classified instances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Gr04xWLgF38"
      },
      "source": [
        "**Testing / Conclusions**\n",
        "\n",
        "**Positive and Negative Words**\n",
        "\n",
        "Let‚Äôs delve into which words have the highest impact on class separation. Here we are translating our numbers back into words, getting the coefficients outputted by the regression, adding them both into a dataframe, and sorting them by their coefficient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eH-RbgXgDOb",
        "outputId": "4318e3c1-9d55-4836-c36c-0133cbbd00b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "#creating array variable of all the words\n",
        "feature_names = np.array(vect.get_feature_names())\n",
        "#creating array of all the regression coefficients per word\n",
        "coef_index = model.coef_[0]\n",
        "#creating df with both arrays in it\n",
        "df = pd.DataFrame({'Word':feature_names, 'Coef': coef_index})\n",
        "#sorting by coefficient\n",
        "df.sort_values('Coef')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8473</th>\n",
              "      <td>worst</td>\n",
              "      <td>-3.065365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8269</th>\n",
              "      <td>waste</td>\n",
              "      <td>-2.451746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5766</th>\n",
              "      <td>poor</td>\n",
              "      <td>-2.429334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5550</th>\n",
              "      <td>pathetic</td>\n",
              "      <td>-2.329705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7258</th>\n",
              "      <td>stopped</td>\n",
              "      <td>-2.190887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4656</th>\n",
              "      <td>love</td>\n",
              "      <td>2.047238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5177</th>\n",
              "      <td>nice</td>\n",
              "      <td>2.183999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1252</th>\n",
              "      <td>best</td>\n",
              "      <td>2.410673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2994</th>\n",
              "      <td>excellent</td>\n",
              "      <td>2.603525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>985</th>\n",
              "      <td>awesome</td>\n",
              "      <td>3.081720</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8612 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Word      Coef\n",
              "8473      worst -3.065365\n",
              "8269      waste -2.451746\n",
              "5766       poor -2.429334\n",
              "5550   pathetic -2.329705\n",
              "7258    stopped -2.190887\n",
              "...         ...       ...\n",
              "4656       love  2.047238\n",
              "5177       nice  2.183999\n",
              "1252       best  2.410673\n",
              "2994  excellent  2.603525\n",
              "985     awesome  3.081720\n",
              "\n",
              "[8612 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ4QPaSzgWwy"
      },
      "source": [
        "**Negative Sentiment:**\n",
        "\n",
        "'worst' is the most negatively correlated word. The rest of the 4 words also make sense as they all concey negative emotion toward the product"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1DvNjOCge3N"
      },
      "source": [
        "**Positive Sentiment:**\n",
        "\n",
        "As you move down the dataframe, the words become more positively correlated.\n",
        "\n",
        "'awesome' is the highest, it has relatively the same weight as 'worst'.\n",
        "\n",
        "The rest of the positively correlated words are intuitively showing positive emotion toward the product.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK4aZOplgoQP"
      },
      "source": [
        "**Testing custom reviews**\n",
        "\n",
        "Lastly, we can experiment and test our own custom reviews. In bold below are the inputs and beneath that are the respective outputs (1 = positive; 0 = negative). The reason the first one came out as positive might be that the coefficient correlated with 'great' is higher than that correlated with 'abandoned' and hence a positive 1 is returned. The rest of the classification seem to be accurate except for the 6th one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx38ABNCguOq",
        "outputId": "8d267180-457c-45e5-d182-88431a515875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(model.predict(vect.transform(['abandoned great'])))\n",
        "print(model.predict(vect.transform(['Who doesn‚Äôt love a clean car? If your driver takes great care of theirs, go ahead and say thanks.'])))\n",
        "print(model.predict(vect.transform(['great she the best'])))\n",
        "print(model.predict(vect.transform(['cool, safe, fun'])))\n",
        "print(model.predict(vect.transform(['charged slow horrible'])))\n",
        "print(model.predict(vect.transform(['it was as average as a trip could be'])))\n",
        "print(model.predict(vect.transform(['my family felt safe we got to our destination with ease'])))\n",
        "print(model.predict(vect.transform(['i got to my destination quickly and affordably i had a smile on my face from start to finish'])))\n",
        "print(model.predict(vect.transform(['hard, bad, cool'])))\n",
        "print(model.predict(vect.transform(['000'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[0]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[0]\n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h7ZlyoABMCA",
        "outputId": "08f647a9-1a31-4965-cffe-52d10c53425f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(model.predict(vect.transform([\"I bought this phone and it came in its usual packaging but not factory sealed. Just a yellow sticker. During setup, everything was in Spanish and I switched it to English and followed through with the setup. Even after setup, many apps were in Spanish. I put my Straight Talk SIM card in and nothing. I couldn't text, call, browse, etc. I'm pretty sure I was sent an International phone. I also kept getting a message that said Open channel for BIP. I had no issues with my Galaxy S9 Plus. For $999, you'd think they'd sent the right product. It's a shame because the phone I ordered was beautiful but useless.\"])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jNJfIzdUHAD"
      },
      "source": [
        "Learning - The fit of the model depends on the quality of the dataset we obtain. The better the quality of the data, the more accurate the model's classification will be."
      ]
    }
  ]
}